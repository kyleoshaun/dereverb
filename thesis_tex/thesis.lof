\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Block diagram for supervised optimal filtering, which attempts to produce a desired output, $d(n)$, from a known input, $x(n)$}}{79}{figure.caption.7}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Block diagram for supervised inverse filtering / equalization, which attempts to produce reproduce the known input, $s(n)$, to an unknown system $G(z)$, from the measured system output, $m(n)$, using a filter, $H(z)$}}{80}{figure.caption.8}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Block diagram for supervised blind deconvolution, which attempts to produce reproduce the unknown input, $s(n)$, to an unknown system $G(z)$, from the measured system output, $m(n)$, including additive noise $v(n)$, using a filter, $H(z)$}}{85}{figure.caption.9}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces MINT equalizer performance for various equalizer orders relative to the actual length of the FIR channel (L) and the number of samples corresponding to the T60 of the channel (N60 = T60 * sample rate))}}{90}{figure.caption.10}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Source whitening results using a p1 = 4000 order linear predictor. The prediction error filter coefficients were computed based on clean speech and the same filter was used in all tests in this section to assess the multichannel prediction stage of the delay-and-predict algorithm in isolation.}}{91}{figure.caption.11}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Delay-and-Predict dereverberation performance with multichannel linear prediction order p2 = L / (M-1), where L is the FIR RIR length and M is the number of channels. Figure \ref {fig:params_p2_stage1} shows the common source whitening filter used.}}{92}{figure.caption.12}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Delay-and-Predict dereverberation performance with various multichannel linear prediction orders (p2) relative to the actual length of the FIR channel (L) and the number of samples corresponding to the T60 of the channel (N60). Figure \ref {fig:params_p2_stage1} shows the common source whitening filter used.}}{93}{figure.caption.13}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Delay-and-Predict dereverberation performance with source whitening prediction order p1 = 200 and multichannel linear prediction order p2 = N60 / (M-1).}}{95}{figure.caption.14}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Delay-and-Predict dereverberation performance with various source whitening prediction orders (p1) relative to the multichannel linear prediction order p2 = N60 / (M-1)}}{96}{figure.caption.15}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces MINT Equalizer performance (EDC and Spectrogram)}}{97}{figure.caption.16}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Delay-and-Predict Equalizer performance (EDC and Spectrogram) with the source-whitening filter computed using clean speech (i.e., not blind)}}{97}{figure.caption.17}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Delay-and-Predict Equalizer performance (EDC and Spectrogram) with the source-whitening filter computed using reverberant speech (i.e., blind)}}{98}{figure.caption.18}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Delay-and-Predict dereverberation performance with the same speech sample (SA1.WAV, 58061 samples) looped to various data lengths to preserve the same spectrum. Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source Whitening stage was performed on revererbant speech (i.e., blind).}}{99}{figure.caption.19}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Delay-and-Predict dereverberation performance with the source signal generated by looping various length white noise sequences looped the same data length (i.e., same data length, different spectra). Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source Whitening stage was performed on revererbant speech (i.e., blind).}}{101}{figure.caption.20}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Delay-and-Predict dereverberation performance with the source signal generated by filtering 60 msec of speech with filters of various peakiness. Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source Whitening stage was performed on revererbant speech (i.e., blind).}}{102}{figure.caption.21}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces Showing the impact of RIR time alignment on multichannel linear prediction performance. The RIRs (left column) were synthetically generated exponentially decaying gaussians and an incremental delay of 2 samples was added to each channel. The right column shows the result of each individual prediction error filter (i.e., the top-most one is the result of predicting the current sample of microphone 1 from the past samples of microphones 1-4)}}{103}{figure.caption.22}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces Delay-and-Predict dereverberation performance an incremental 2 sample delay added to each channel.}}{104}{figure.caption.23}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces Repeating with no time delay}}{104}{figure.caption.24}%
\contentsline {figure}{\numberline {3.16}{\ignorespaces Delay-and-Predict dereverberation performance for perfectly time-aligned RIRs}}{105}{figure.caption.25}%
\contentsline {figure}{\numberline {3.17}{\ignorespaces Analysis of the computational complexities of Least Squares solution and Inverse filter implementations as a function of T60, For M=4 microphones, p2 = N60/(M-1) and p1 = 1.25*p2*(M-1). Complexity of LMS Solution also shown for comparison.}}{105}{figure.caption.26}%
\contentsline {figure}{\numberline {3.18}{\ignorespaces Analysis of the algorithmic memory requirements of Least Squares solution (could be temporary memory) and Inverse filter implementations (persistent memory) as a function of T60, For M=4 microphones, p2 = N60/(M-1) and p1 = 1.25*p2*(M-1). Memory requirements of LMS Solution also shown for comparison.}}{106}{figure.caption.27}%
\contentsline {figure}{\numberline {3.19}{\ignorespaces Delay-and-Predict dereverberation performance with multichannel linear prediction order p2 = N60 / (M-1), where N60 is the number of samples corresponding to the T60 and M is the number of channels (i.e., the MINT condition based on T60 rather than the FIR RIR length). Figure \ref {fig:params_p2_stage1} shows the common source whitening filter used.}}{107}{figure.caption.28}%
\contentsline {figure}{\numberline {3.20}{\ignorespaces Delay-and-Predict dereverberation performance with multichannel linear prediction order p2 = 0.75 * N60 / (M-1), where N60 is the number of samples corresponding to the T60 and M is the number of channels (i.e., suboptimal with respect to the MINT condition based on T60 rather than the FIR RIR length). Figure \ref {fig:params_p2_stage1} shows the common source whitening filter used.}}{107}{figure.caption.29}%
\contentsline {figure}{\numberline {3.21}{\ignorespaces Delay-and-Predict dereverberation performance with multichannel linear prediction order p2 = 0.5 * N60 / (M-1), where N60 is the number of samples corresponding to the T60 and M is the number of channels (i.e., More suboptimal with respect to the MINT condition based on T60 rather than the FIR RIR length). Figure \ref {fig:params_p2_stage1} shows the common source whitening filter used.}}{108}{figure.caption.30}%
\contentsline {figure}{\numberline {3.22}{\ignorespaces Delay-and-Predict dereverberation performance with source whitening prediction order p1 = 1000 and multichannel linear prediction order p2 = N60 / (M-1).}}{109}{figure.caption.31}%
\contentsline {figure}{\numberline {3.23}{\ignorespaces Delay-and-Predict dereverberation performance with source whitening prediction order p1 = p2 * (M-1) and multichannel linear prediction order p2 = N60 / (M-1). I.e., The source whitening filter order is the same as the effective MINT filter order.}}{110}{figure.caption.32}%
\contentsline {figure}{\numberline {3.24}{\ignorespaces Delay-and-Predict dereverberation performance with source whitening prediction order p1 = 2 * p2 * (M-1) and multichannel linear prediction order p2 = N60 / (M-1). I.e., The source whitening filter order is twice the effective MINT filter order.}}{111}{figure.caption.33}%
\contentsline {figure}{\numberline {3.25}{\ignorespaces Delay-and-Predict dereverberation performance for a 3.6 second speech source (58061 samples). Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source whitening filter was estimated using clean speech.}}{112}{figure.caption.34}%
\contentsline {figure}{\numberline {3.26}{\ignorespaces Delay-and-Predict dereverberation performance for a 3.6 second speech source (58061 samples). Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source whitening filter was estimated using reverberant speech (blind estimation).}}{113}{figure.caption.35}%
\contentsline {figure}{\numberline {3.27}{\ignorespaces Delay-and-Predict dereverberation performance for a 10.9 second speech source (174183 samples). The source was generated by looping the same 3.6 secound source 3 times to maintain the same spectrum. Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source whitening filter was estimated using clean speech.}}{114}{figure.caption.36}%
\contentsline {figure}{\numberline {3.28}{\ignorespaces Delay-and-Predict dereverberation performance for a 10.9 second speech source (174183 samples). The source was generated by looping the same 3.6 secound source 3 times to maintain the same spectrum. Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source whitening filter was estimated using revererant speech (blind estimation).}}{115}{figure.caption.37}%
\contentsline {figure}{\numberline {3.29}{\ignorespaces Delay-and-Predict dereverberation performance with source being 1 second of white noise looped to 60 sec. Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source whitening filter was estimated using clean speech.}}{116}{figure.caption.38}%
\contentsline {figure}{\numberline {3.30}{\ignorespaces Delay-and-Predict dereverberation performance with source being 1 second of white noise looped to 60 sec. Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source whitening filter was estimated using revererant speech (blind estimation).}}{117}{figure.caption.39}%
\contentsline {figure}{\numberline {3.31}{\ignorespaces Delay-and-Predict dereverberation performance with source being 10 second of white noise looped to 60 sec (i.e., source is less peaky than the previous case). Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source whitening filter was estimated using clean speech.}}{118}{figure.caption.40}%
\contentsline {figure}{\numberline {3.32}{\ignorespaces Delay-and-Predict dereverberation performance with source being 10 second of white noise looped to 60 sec (i.e., source is less peaky than the previous case). Source whitening prediction order was p1 = 2 * p2 * (M-1) and multichannel linear prediction order was p2 = N60 / (M-1). Source whitening filter was estimated using revererant speech (blind estimation).}}{119}{figure.caption.41}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces HRIR database office II room}}{122}{figure.caption.42}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces HRIR database courtyard room}}{122}{figure.caption.43}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces HRIR database cafeteria room}}{123}{figure.caption.44}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces MYRiAD database SAL room}}{124}{figure.caption.45}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Impact of EC algorithm on speech intelligibility (using HASPI) as a function of noise direction, anechoic directional speech and noise}}{125}{figure.caption.46}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Impact of EC algorithm on speech intelligibility (using HASPI) as a function of SNR, for anechoic directional speech and various noise types (anechoic directional, reverberant, spatial recording, diffuse)}}{126}{figure.caption.47}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Impact of EC algorithm on speech intelligibility (using HASPI) as a function of SNR, for reverberant speech and various noise types (anechoic directional, reverberant, spatial recording, diffuse)}}{127}{figure.caption.48}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Impact of EC algorithm on speech intelligibility (using HASPI) as a function of SNR, for diffuse speech and various noise types (anechoic directional, reverberant, spatial recording, diffuse)}}{128}{figure.caption.49}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Impact of EC algorithm on speech intelligibility (using HASPI) as a function of varying amounts of synthetic reverb, for spatial noise recording with SNR = \qty {-12}{\decibel } and SNR = \qty {0}{\decibel }}}{129}{figure.caption.50}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Impact of EC algorithm on speech intelligibility (using HASPI) as a function of varying amounts of synthetic reverb, for spatial noise recording with SNR = \qty {-12}{\decibel } }}{130}{figure.caption.51}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces Impact of EC algorithm on speech intelligibility (using HASPI) as a function of varying amounts of synthetic reverb, noise-free}}{131}{figure.caption.52}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces Hearing aid gains to be used in evaluation}}{132}{figure.caption.53}%
\contentsline {figure}{\numberline {4.13}{\ignorespaces Comparison of perceptual benefit of four different linear hearing aid gains in the presence of reverb. Moderate high frequency hearing loss used in the perceptual models (IEC 60118-15 Moderate HL, Moderately Sloping Group), and RIRs were generated synthetically}}{133}{figure.caption.54}%
\contentsline {figure}{\numberline {4.14}{\ignorespaces Impact of synthetic reverberation (exponentially decaying gaussian RIRs) on SI predictors with and without hearing loss. NAL-R linear hearing aid amplification included in hearing loss case for metrics that including modeling of hearing loss}}{134}{figure.caption.55}%
\contentsline {figure}{\numberline {4.15}{\ignorespaces Impact of synthetic reverberation (exponentially decaying gaussian RIRs) with added real early reflections generated by truncating a real RIR (Office II RIR from the HRIR database) on SI predictors with and without hearing loss. NAL-R linear hearing aid amplification included in hearing loss case for metrics that including modeling of hearing loss}}{135}{figure.caption.56}%
\contentsline {figure}{\numberline {4.16}{\ignorespaces Impact of practical reverberation (several real measured RIRs) on SI predictors with and without hearing loss. NAL-R linear hearing aid amplification included in hearing loss case for metrics that including modeling of hearing loss}}{135}{figure.caption.57}%
\contentsline {figure}{\numberline {4.17}{\ignorespaces TODO: REPLOT THIS WITH SAME X-AXIS USED IN ALL PLOTS FOR EDC. Example of how SAL was truncated by applying additional exponential decay as a window to manipulate T60 synthetically}}{136}{figure.caption.58}%
\contentsline {figure}{\numberline {4.18}{\ignorespaces Impact of practical reverberation (SAL room from MYRiAD database exponentially truncated to control T60) on SI predictors with and without hearing loss. NAL-R linear hearing aid amplification included in hearing loss case for metrics that including modeling of hearing loss}}{136}{figure.caption.59}%
\contentsline {figure}{\numberline {4.19}{\ignorespaces Example of how early reflections of SAL RIR were reduced in magnitude (by 6 dB) to make reverberation effect stronger}}{137}{figure.caption.60}%
\contentsline {figure}{\numberline {4.20}{\ignorespaces Impact of reducing early reflections of SAL RIR (i.e., Figure \ref {fig:SAL_ERProcessing_Div2}). SI shown before RIR processing (left) and after RIR processing (right) for comparison}}{137}{figure.caption.61}%
\contentsline {figure}{\numberline {4.21}{\ignorespaces Impact of synthetic reverberation (exponentially decaying gaussian RIRs) on SI predictors with and without hearing loss. NAL-R linear hearing aid amplification included in hearing loss case for metrics that including modeling of hearing loss. Scaling applied to NSIM and STMI values to better view all metrics on the same plot.}}{138}{figure.caption.62}%
\contentsline {figure}{\numberline {4.22}{\ignorespaces Impact of synthetic reverberation (exponentially decaying gaussian RIRs) with added real early reflections generated by truncating a real RIR (Office II RIR from the HRIR database) on SI predictors with and without hearing loss. NAL-R linear hearing aid amplification included in hearing loss case for metrics that including modeling of hearing loss. Scaling applied to NSIM and STMI values to better view all metrics on the same plot.}}{139}{figure.caption.63}%
\contentsline {figure}{\numberline {4.23}{\ignorespaces Impact of practical reverberation (several real measured RIRs) on SI predictors with and without hearing loss. NAL-R linear hearing aid amplification included in hearing loss case for metrics that including modeling of hearing loss. Scaling applied to NSIM and STMI values to better view all metrics on the same plot.}}{139}{figure.caption.64}%
\contentsline {figure}{\numberline {4.24}{\ignorespaces Impact of practical reverberation (SAL room from MYRiAD database exponentially truncated to control T60) on SI predictors with and without hearing loss. NAL-R linear hearing aid amplification included in hearing loss case for metrics that including modeling of hearing loss. Scaling applied to NSIM and STMI values to better view all metrics on the same plot.}}{140}{figure.caption.65}%
\contentsline {figure}{\numberline {4.25}{\ignorespaces Block diagram for method used in evaluating dereverberation algorithm performance. Microphone signals include reverberant speech (MYRiAD SAL RIR windowed exponentially to control T60) with added noise signal (real multichannel noise recordings) and added reverberant interference signal. All SI and SQ predictors were computed for the unprocessed microphone signals and the dereverberation output both with and without hearing loss included in all models of speech perception.}}{141}{figure.caption.66}%
\contentsline {figure}{\numberline {4.26}{\ignorespaces Evaluation of delay-and-predict dereverberation performance as a function of T60. RIRs were synthetically generated by applying a variable decay-rate exponential window to sequences of uncorrelated Gaussian white noise.}}{142}{figure.caption.67}%
\contentsline {figure}{\numberline {4.27}{\ignorespaces Evaluation of delay-and-predict dereverberation performance as a function of T60. RIRs were generated by applying a variable decay-rate exponential window to a measured RIR (The SAL room from the MYRiAD database, T60 = 2.2 sec) to control T60.}}{144}{figure.caption.68}%
\contentsline {figure}{\numberline {4.28}{\ignorespaces Evaluation of delay-and-predict dereverberation performance in the presence of noise as a function of T60. RIRs were generated by applying a variable decay-rate exponential window to a measured RIR (The SAL room from the MYRiAD database, T60 = 2.2 sec) to control T60. Noise was a multichannel recording of approximately stationary noise (Office ventillation noise from the HRIR database), and SNR was set to 12 dB.}}{146}{figure.caption.69}%
\contentsline {figure}{\numberline {4.29}{\ignorespaces Evaluation of delay-and-predict dereverberation performance in the presence of noise as a function of SNR. RIRs were generated by applying a variable decay-rate exponential window to a measured RIR (The SAL room from the MYRiAD database, T60 = 2.2 sec) to set T60 = 1 second. Noise was a multichannel recording of approximately stationary noise (Office ventillation noise from the HRIR database).}}{148}{figure.caption.70}%
\contentsline {figure}{\numberline {4.30}{\ignorespaces Evaluation of delay-and-predict dereverberation performance in the presence of noise as a function of SNR. RIRs were generated by applying a variable decay-rate exponential window to a measured RIR (The SAL room from the MYRiAD database, T60 = 2.2 sec) to set T60 = 1 second. Noise was a multichannel recording of non-stationary noise (Cafeteria babble noise from the HRIR database).}}{150}{figure.caption.71}%
\contentsline {figure}{\numberline {4.31}{\ignorespaces Evaluation of delay-and-predict dereverberation performance in the presence of an interfering talker, as a function of T60. RIRs were generated by applying a variable decay-rate exponential window to a measured RIR (The SAL room from the MYRiAD database, T60 = 2.2 sec) to control T60. Similarly, a measured RIR from a different location in the room was exponentially windowed and used for the interfering talker. The primary-to-interfering talker ratio, i.e., signal-to-interference ratio, was set to SIR = 12 dB.}}{152}{figure.caption.72}%
\addvspace {10\p@ }
